import 'dart:async';
import 'dart:developer' as dev;
import 'dart:io';
import 'dart:typed_data';
import 'package:record/record.dart';
import 'package:path_provider/path_provider.dart';
import 'dart:math';
import 'package:intl/intl.dart';
// â† Fileã‚„Directoryã‚’ä½¿ã£ã¦ã„ã‚‹å ´åˆ

class AudioRecorderService {
  final AudioRecorder _recorder = AudioRecorder();
  String? _filePath;
  String? recordedFilePath;
  bool isRecording = false;
  StreamSubscription<RecordState>? _stateSubscription;

  double _maxObservedAmplitude = 0.0;

  String? get getRecordedFilePath => recordedFilePath;

  // ğŸ”Š æŒ¯å¹…ã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼ˆ0ã€œ1ã«æ­£è¦åŒ–ï¼‰
  Stream<double> get amplitudeStream => _recorder
          .onAmplitudeChanged(const Duration(milliseconds: 100))
          .map((event) {
        double amplitude = event.current;
        double normalized = (amplitude + 160) / 160;
        double boosted = (normalized - 0.6) * 10;
        final value = boosted.clamp(0.0, 1.0);

        if (value > _maxObservedAmplitude) {
          _maxObservedAmplitude = value;
          dev.log('ğŸ“ˆ æœ€å¤§æŒ¯å¹…æ›´æ–°: $_maxObservedAmplitude');
        }

        dev.log('ğŸ¤ Raw: $amplitude, Normalized: $normalized, Boosted: $value');
        return value;
      });

  // ğŸ™ï¸ éŒ²éŸ³é–‹å§‹
  Future<void> startRecording({
    required String level,
    required String title,
    String? path,
  }) async {
    try {
      final bool hasPermission = await _recorder.hasPermission();
      if (!hasPermission) throw Exception("éŒ²éŸ³ã®è¨±å¯ãŒã‚ã‚Šã¾ã›ã‚“");

      final savePath =
          path ?? await getSavePath(level: level, title: title); // â† è‡ªå‹•ç”Ÿæˆ
      _filePath = savePath;

      await _recorder.start(
        RecordConfig(encoder: AudioEncoder.wav),
        path: _filePath!,
      );

      isRecording = true;
      recordedFilePath = null;
      _maxObservedAmplitude = 0.0;

      _stateSubscription?.cancel();
      _stateSubscription = _recorder.onStateChanged().listen((state) {
        if (state == RecordState.record) {
          dev.log("ğŸ¤ éŒ²éŸ³ä¸­...");
        }
      });
    } catch (e) {
      dev.log("âŒ éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼: $e");
    }
  }

  // ğŸ›‘ éŒ²éŸ³åœæ­¢
  Future<String?> stopRecording() async {
    try {
      String? filePath = await _recorder.stop();
      dev.log("ğŸ¤ éŒ²éŸ³åœæ­¢: $filePath");

      isRecording = false;
      if (filePath != null) {
        recordedFilePath = filePath;

        final size = await File(filePath).length();
        dev.log("ğŸ“¦ éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: $size bytes");
      }

      dev.log("âœ… ã“ã®éŒ²éŸ³ã®æœ€å¤§æŒ¯å¹…: $_maxObservedAmplitude");

      await _stateSubscription?.cancel();
      _stateSubscription = null;

      return filePath;
    } catch (e) {
      dev.log("âŒ éŒ²éŸ³åœæ­¢ã‚¨ãƒ©ãƒ¼: $e");
      return null;
    }
  }

  // ğŸ“ ãƒ‘ã‚¹ç”Ÿæˆ
  // ğŸ“ ãƒ‘ã‚¹ç”Ÿæˆï¼ˆå®‰å…¨ãªãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
  Future<String> getSavePath({
    required String level,
    required String title,
  }) async {
    final dir = await getApplicationDocumentsDirectory();
    final recordingDir = Directory('${dir.path}/shadow_speak/recordings');

    if (!await recordingDir.exists()) {
      await recordingDir.create(recursive: true);
    }

    final timestamp = DateFormat('yyyyMMdd_HHmmss').format(DateTime.now());

    // ã‚¹ãƒšãƒ¼ã‚¹ â†’ ãƒã‚¤ãƒ•ãƒ³ ã«å¤‰æ›ã—ã¦ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã‚’ __ ã«çµ±ä¸€
    final safeLevel = level.replaceAll(' ', '-');
    final safeTitle = title.replaceAll(' ', '-');

    return '${recordingDir.path}/$safeLevel\_\_${safeTitle}\_\_${timestamp}.wav';
  }

  // ğŸ“Š æ³¢å½¢æŠ½å‡º
  Future<List<double>> extractWaveform(
      File file, Duration audioDuration) async {
    final List<double> waveform = [];
    try {
      final Uint8List data = await file.readAsBytes();
      int totalSamples = data.length ~/ 2;

      if (audioDuration.inSeconds == 0) {
        dev.log("âš ï¸ audioDurationãŒ0ç§’ã®ãŸã‚æ³¢å½¢æŠ½å‡ºã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚");
        return [];
      }

      int desiredSamples = audioDuration.inSeconds * 100;
      int groupSize = (totalSamples / desiredSamples).ceil();

      final ByteData byteData = ByteData.sublistView(data);

      for (int i = 0; i < totalSamples; i += groupSize) {
        int end = (i + groupSize).clamp(0, totalSamples);
        double sum = 0.0;
        int count = 0;

        for (int j = i; j < end; j++) {
          int sample = byteData.getInt16(j * 2, Endian.little);
          double normalized = sample.abs() / 327.68;
          sum += normalized;
          count++;
        }

        waveform.add(count > 0 ? sum / count : 0.0);
      }

      if (waveform.isEmpty) {
        dev.log("âš ï¸ waveformãŒç©ºã§ã™ã€‚æŠ½å‡ºã«å¤±æ•—ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚");
      } else {
        dev.log(
            "ğŸ” waveformã®æœ€åˆã®20å€‹: ${waveform.take(20).map((v) => v.toStringAsFixed(2)).toList()}");
        dev.log("ğŸ“ waveformã®æœ€å¤§å€¤: ${waveform.reduce(max).toStringAsFixed(2)}");
        dev.log("ğŸ“Š waveformã®é•·ã•: ${waveform.length}");
      }
    } catch (e) {
      dev.log("âš ï¸ æ³¢å½¢æŠ½å‡ºå¤±æ•—: $e");
    }

    return waveform;
  }

  Future<void> stop() async {
    await stopRecording();
  }

  void dispose() {
    _stateSubscription?.cancel();
  }
}
